---
date: '2025-02-10'
title: 'Information Retrieval Evaluation with Hybrid Humanâ€“Synthetic Labels'
cover: './cover.png'
tech:
  - Python
  - TF-IDF
  - scikit-learn
github: ''
external: '/slides/IR_CPSC.pdf'
cta: ''
---

Improved ranking evaluation reliability by combining synthetic relevance labels with targeted human-corrected judgments, increasing nDCG@10 by 28%.

Demonstrated that limited human feedback can significantly improve evaluation quality while keeping labeling effort low.
